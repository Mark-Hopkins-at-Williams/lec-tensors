{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Tensors and Torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    In mathematics, a tensor is an arbitrarily complex geometric object that maps in a multi-linear manner geometric vectors, scalars, and other tensors to a resulting tensor.\n",
    "    \n",
    "    -- Wikipedia\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's another excerpt from the Wikipedia article on tensors:\n",
    "\n",
    "    Although seemingly different, the various approaches to defining tensors describe the same geometric concept using different language and at different levels of abstraction. A tensor may be represented as a (potentially multidimensional) array (although a multidimensional array is not necessarily a representation of a tensor, as discussed below with regard to holors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this class, when we say **tensor**, we will just mean **a multidimensional array**. But the term **dimension** can get confusingly overloaded here. Let's see why.\n",
    "\n",
    "A 1-dimensional tensor is just a vector. In this class, we'll predominantly be using the ```torch``` package for manipulating tensors. In ```torch```, we create a vector as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "v = tensor([4, 5, 6, 7, 8])\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, but then this ends up being described as a vector of dimension 5, or **a 1-dimensional tensor of dimension 5**. Which is super confusing. So typically, we will refer to these separate concepts as the **order** and the **shape**. So this is an **order-1 tensor of shape (5)**. We can get these numbers from the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The order of the tensor is {}.'.format(v.dim()))\n",
    "print('The shape of the tensor is {}.'.format(v.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that ```.shape``` is an attribute of the tensor, not a method call. You can get parts of vectors in a similar way you would for Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v[:3])\n",
    "print(v[2:])\n",
    "print(v[2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** what's a simple way to extract the vector ```[4, 6, 8]```?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass # returns tensor([4, 6, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important special case is converting an order-1 tensor into a scalar. In ```torch```, they recommend doing this using ```.item()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tensor([12])\n",
    "w.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that ```.item()``` will throw an exception if you apply it to a non-singleton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An order-2 tensor is a **matrix**. Here's how we would create a matrix with 4 rows and 3 columns using ```torch```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "M = tensor([[4, 5, 6], [7, 8, 9], [10, 11, 12], [13, 14, 15]])\n",
    "print(M)\n",
    "print('The order of M is {}.'.format(M.dim()))\n",
    "print('The shape of M is {}.'.format(M.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we get submatrices? It's sort of like the syntax for getting parts of Python lists, though a bit weird to get used to. Commas are involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M) \n",
    "print(M[:2]) # first two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M) \n",
    "print(M[2:]) # last two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M) \n",
    "print(M[0::2]) # every second row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M) \n",
    "print(M[:,:2]) # first two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M) \n",
    "print(M[:,2:3]) # last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M) \n",
    "print(M[:,0::2]) # every second column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** How do you extract ```tensor([[7, 9], [10, 12]])``` from ```M```?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M)\n",
    "raise Exception('Complete exercise before proceeding!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do the usual elementwise operations on matrices, and transpose them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M)\n",
    "print(M+M)\n",
    "print(3*M)\n",
    "print(M*M) # note: this is elementwise multiplication (sometimes called Hadamard product), not matrix multiplication!\n",
    "print(M.t()) # matrix transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do standard matrix multiplication with ```torch.mm```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.mm(M, M.t()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You cannot however multiply a matrix and a vector using `mm`. However there is another function called `mv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M)\n",
    "v = tensor([1, 2, 3])\n",
    "torch.mm(M, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mv(M, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One option is to ```unsqueeze``` the length 3 vector into a 3x1 matrix and then call `mm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tensor([1, 2, 3])\n",
    "print(\"Before unsqueezing:\")\n",
    "print(v)\n",
    "v = v.unsqueeze(1)\n",
    "print(\"\\nAfter unsqueezing:\")\n",
    "print(v)\n",
    "torch.mm(M, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsqueezing increases the order of a tensor by 1. The argument to ```unsqueeze``` tells us where to put the new dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original shape of M:  {M.shape}\")\n",
    "M_prime = M.unsqueeze(0)\n",
    "print(f\"After M.unsqueeze(0): {M_prime.shape}\")\n",
    "print(M_prime)\n",
    "M_prime = M.unsqueeze(1)\n",
    "print(f\"After M.unsqueeze(1): {M_prime.shape}\")\n",
    "print(M_prime)\n",
    "M_prime = M.unsqueeze(2)\n",
    "print(f\"After M.unsqueeze(2): {M_prime.shape}\")\n",
    "print(M_prime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the tensor's shape contains a dimension of size 1, then you can squeeze that dimension to remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_prime = tensor([[[ 4,  5,  6],\n",
    "                   [ 7,  8,  9],\n",
    "                   [10, 11, 12],\n",
    "                   [13, 14, 15]]])\n",
    "print(f\"Shape of M_prime: {M_prime.shape}\")\n",
    "M_prime = M_prime.squeeze(0)\n",
    "print(f\"After squeezing:  {M_prime.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One issue that is likely going to bite you again and again is the datatype of tensors, which tells you what the entries of the tensors are: usually either floating point (of some kind) or integer (of some kind). ```torch``` does its best to guess what you want, but it's not psychic. For the matrix ```M2```, it assumes that because all the initialized entries are integers, then we want a matrix with an integer datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2 = tensor([[4,5,6],[2,8,9],[1,7,3]])\n",
    "print(M2.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But maybe we wanted these to be floating point, and unsuspectingly try to take the matrix inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.inverse(M2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially it's complaining that a matrix of datatype ```torch.int64``` (a so-called ```LongTensor```) can't be inverted, because there's no integer matrix ```M^-1``` by which we can multiply it such that ```M * M^-1 = I```. So we need to tell it explicitly that we want to treat matrix ```M``` as a floating-point matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2 = M2.float()\n",
    "M2inv = torch.inverse(M2)\n",
    "print(M2inv)\n",
    "I = M2.mm(M2inv)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** How do we convert this back to a LongTensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('Complete exercise before proceeding!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```reshape``` is a kind of magical operation that repacks the elements of a matrix into a different shape by copying the elements row by row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M)\n",
    "print(M.reshape((2, 6)))\n",
    "print(M.reshape(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```torch``` supports the notion of **broadcasting**, which allows us to conveniently use elementwise operators over tensors of different orders. For instance, if we add a vector ```v``` of shape (3) to a matrix ```M``` of shape (4,3), then ```torch``` assumes that we want to add two (4,3) matrices. One is just ```M```. The other is 4 copies of vector ```v``` piled on top of each other to make another (4,3) matrix. Surprisingly this turns out to be useful. In general, you can use broadcasting to apply elementwise operations if one tensor has shape (a, b, ... n, n + 1, ... m) and the other has shape (n, n + 1, ... m). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tensor([[4, 5, 6], [7, 8, 9], [10, 11, 12], [13, 14, 15]])\n",
    "B = tensor([[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]])\n",
    "print(\"A is:\")\n",
    "print(A)\n",
    "print(\"B is:\")\n",
    "print(B)\n",
    "print(\"A + B is:\")\n",
    "print(A+B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tensor([[4, 5, 6], [7, 8, 9], [10, 11, 12], [13, 14, 15]])\n",
    "b = tensor([1, 2, 3])\n",
    "print(\"A is:\")\n",
    "print(A)\n",
    "print(\"b is:\")\n",
    "print(b)\n",
    "print(\"A + b is:\")\n",
    "print(A+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's turn out attention to order-3 tensors. One useful order-3 tensor is an RGB image file. Consider this image of the Swiss flag:\n",
    "\n",
    "![swiss flag](img/swiss.gif \"Swiss flag\")\n",
    "\n",
    "We can view the pixels as a 5x5 matrix. If this were a black-and-white image, it would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWISS_FLAG_BW = tensor([[0,0,0,0,0],[0,0,1,0,0],[0,1,1,1,0],[0,0,1,0,0],[0,0,0,0,0]])\n",
    "print(SWISS_FLAG_BW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it isn't a black-and-white image, it's a color image, which means that for each pixel, there's a red value (from 0-255), a green value (from 0-255), and a blue value (from 0-255)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Represent the Swiss flag as an order-three tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWISS_FLAG = pass # TODO: complete this line\n",
    "print(SWISS_FLAG)\n",
    "print('The Swiss flag has shape: {}.'.format(SWISS_FLAG.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it can be easier to use torch's tensor concatenation operations to construct these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWISS_FLAG_RED = tensor( [ [255,255,255,255,255],\n",
    "                           [255,255,255,255,255],\n",
    "                           [255,255,255,255,255],\n",
    "                           [255,255,255,255,255],\n",
    "                           [255,255,255,255,255]])\n",
    "\n",
    "SWISS_FLAG_GREEN = tensor([[0,0,0,0,0],\n",
    "                           [0,0,255,0,0],\n",
    "                           [0,255,255,255,0],\n",
    "                           [0,0,255,0,0],\n",
    "                           [0,0,0,0,0]])\n",
    "\n",
    "SWISS_FLAG_BLUE  = tensor([[0,0,0,0,0],\n",
    "                           [0,0,255,0,0],\n",
    "                           [0,255,255,255,0],\n",
    "                           [0,0,255,0,0],\n",
    "                           [0,0,0,0,0]])\n",
    "\n",
    "SWISS_FLAG = torch.stack([SWISS_FLAG_RED, SWISS_FLAG_GREEN, SWISS_FLAG_BLUE])\n",
    "print(SWISS_FLAG)\n",
    "print('The Swiss flag has shape: {}.'.format(SWISS_FLAG.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually display this image in this notebook using a plotting library called ```matplotlib``` (which, if you don't have, make sure you ```pip install matplotlib```). The problem is, it expects the image tensor to have shape (5,5,3), rather than (3,5,5). In other words, rather than (x,y,color) coordinates, it expects (color,x,y) coordinates. Luckily, higher-order tensors have generalized transpose operations that swap arbitrary axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = tensor([[[1,2], [3,4]], [[5,6], [7,8]]])\n",
    "print(f\"T has size {T.shape}.\")\n",
    "print(\"\\nThis is T:\")\n",
    "print(T)\n",
    "print(\"\\nThis is T, after transposing dimensions 0 and 1:\")\n",
    "print(T.transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is T:\")\n",
    "print(T)\n",
    "print(\"\\nThis is T, after transposing dimensions 0 and 2:\")\n",
    "print(T.transpose(0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is T:\")\n",
    "print(T)\n",
    "print(\"\\nThis is T, after transposing dimensions 1 and 2:\")\n",
    "print(T.transpose(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Convert the Swiss flag into an image tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "new_flag = SWISS_FLAG.transpose(0, 1).transpose(1, 2) # TODO: complete this line!\n",
    "print('The original flag shape: {}.'.format(SWISS_FLAG.shape))\n",
    "print('The modified flag shape: {}.'.format(new_flag.shape))\n",
    "imshow(new_flag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you think of an example of an order-3 tensor, famous in pop culture? Hint, its shape is (3, 3, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"RUBIK'S CUBE\"\n",
    "\n",
    "def submit(response):\n",
    "    import rpyc\n",
    "    c = rpyc.connect(\"137.165.10.56\", 18861)\n",
    "    print(c.root.submit_response('lec1', response))\n",
    "\n",
    "print('You submit the password {} to the server.'.format(example))\n",
    "submit(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This tutorial is now complete. Please proceed to do Lab 0 (\"Rubik\") from the Github Classroom:**\n",
    "\n",
    "https://classroom.github.com/a/X0Cljc2-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
